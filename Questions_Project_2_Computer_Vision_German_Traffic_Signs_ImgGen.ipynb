{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Questions - Project 2 - Computer Vision - German Traffic Signs ImgGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namithmaroli/German-Credit-Data/blob/master/Questions_Project_2_Computer_Vision_German_Traffic_Signs_ImgGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9jAqShELHZI"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)\n",
        "\n",
        "Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkFT8HtCZHS"
      },
      "source": [
        "# German Traffic Sign Recognition\n",
        "Multi-class, single-image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJWdbMALTcGJ"
      },
      "source": [
        "### Dataset\n",
        "The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011. They cordially invite researchers from relevant fields to participate: The competition is designed to allow for participation without special domain knowledge. Their benchmark has the following properties:\n",
        "\n",
        "- Single-image, multi-class classification problem\n",
        "- More than 40 classes\n",
        "- More than 50,000 images in total\n",
        "- Large, lifelike database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRhJulWyIGMN"
      },
      "source": [
        "#### Notes\n",
        "- You can check “Meta” folder for getting information about the classes.\n",
        "- If the model is taking too much time to get trained then you can reduce the number of classes. There are around 43 classes in the dataset, model should be trained on a minimum of 15 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC37j3FUDVYd"
      },
      "source": [
        "### Initialize ImageDataGenerator (5 Marks)\n",
        "- Rescale the images\n",
        "- Specify value for validation_split & get 75% data in training and 25% data in validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OakETLlCBwy1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "#import tensorflow.keras.utils.np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.color import rgb2grey"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNpBS7AFDn1r",
        "outputId": "2cced385-937e-4b4f-9ae6-84e04d33ea32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgHNp6kqE4dE"
      },
      "source": [
        "project_path=('/content/drive/My Drive/Computer Vision with CNN/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdTFas5Xh3xS"
      },
      "source": [
        "from zipfile import ZipFile                               #Unzipping zipped file\n",
        "path=project_path + 'German Traffic Sign Recognition.zip'\n",
        "with ZipFile (path,'r') as z:\n",
        "     z.extractall()                                       #Extracting the zipped files\n",
        "     "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bngARzjFNmz"
      },
      "source": [
        "#Defining parameter\n",
        "image_hight = 32\n",
        "image_width = 32\n",
        "image_depth = 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FFQUUPNuHSn"
      },
      "source": [
        "Initializing ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqocQZIRGZoP"
      },
      "source": [
        "Rescaling and Splitting data into train test using DataImageGenerator,splitting ratio is 75:25 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbgNNIT-FNqj"
      },
      "source": [
        "\n",
        "img_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,          #Rescaling     \n",
        "                                                              validation_split=0.25)   #Splitting train and test in 75:25 ratio"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e4ODapEVdx"
      },
      "source": [
        "### Get training data from ImageDataGenerator (5 Marks)\n",
        "- Give directory path\n",
        "- Give target size\n",
        "- Give batch_size\n",
        "- Specify classes, if you wish to use less number of classes you need to give class names in a list (Atleast 15 classes should be there)\n",
        "- Specify class_mode\n",
        "- Specify color_mode\n",
        "- Specify subset\n",
        "\n",
        "You can get details here\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-8qphLVKtGK",
        "outputId": "3f4e14f4-33c2-40f3-c2e5-23ed0625d45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Building training generator\n",
        "train_generator=img_generator.flow_from_directory('/content/Train',\n",
        "                                                  target_size=(image_hight,image_width),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  color_mode='grayscale',\n",
        "                                                  subset='training',\n",
        "                                                  batch_size=32,\n",
        "                                                  seed=42)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22124 images belonging to 33 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPxZ0HIlXlR6",
        "outputId": "85437f96-e539-42a3-d2bc-608018cb4016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "X_train,y_train=next(train_generator)\n",
        "print('Train shape', X_train.shape)\n",
        "print('Label shape', y_train.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape (32, 32, 32, 1)\n",
            "Label shape (32, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9elHCfDoYu_c",
        "outputId": "197bb00c-f268-4ab7-cda0-9bacce6698d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzYNcoV9Gawj"
      },
      "source": [
        "### Get validation data from ImageDataGenerator (5 Marks)\n",
        "- Give directory path\n",
        "- Give target size\n",
        "- Give batch_size\n",
        "- Specify classes, if you wish to use less number of classes you need to give class names in a list (Atleast 15 classes should be there)\n",
        "- Specify class_mode\n",
        "- Specify color_mode\n",
        "- Specify subset\n",
        "\n",
        "You can get details here\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m9zfw0AHIma"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xlnLodNFNuH",
        "outputId": "3637bed5-750f-43cf-d8d7-06149f945b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Building test generator\n",
        "test_generator=img_generator.flow_from_directory('/content/Train',\n",
        "                                                 target_size=(image_hight,image_width),\n",
        "                                                 class_mode=None,\n",
        "                                                 subset='validation',\n",
        "                                                 batch_size=32,\n",
        "                                                 seed=42)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7364 images belonging to 33 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ZlT_4sycJP",
        "outputId": "f3c030b0-4aa8-40f5-f1f2-5160185d231e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "X_test,y_test=next(test_generator)\n",
        "print('Train shape', X_test.shape)\n",
        "print('Label shape', y_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-02797c0cb720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrgEFQeCxa8D",
        "outputId": "def65a87-5ada-4367-f07b-03c23b8f1ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "print('Test image shape: 'X_test.shape)\n",
        "print('Test lable shape: 'y_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-d23fcd4e3cc2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print('Test image shape: 'X_test.shape)\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2fXxJz1I_SV"
      },
      "source": [
        "### Define model (5 Marks)\n",
        "- Initialize a Sequential Model\n",
        "- Add Convolution, Maxpool, Dropout, Flatten & Dense layers according to your model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fns3rEJ-DHQq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRs36YJgJvI0"
      },
      "source": [
        "### Compile the model (2 Marks)\n",
        "- Specify optimizer, loss & metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvgO3JPvDQpL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_Q6ihfUJ6Hm"
      },
      "source": [
        "### Get model summary (2 Marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3Sxnbo-lhfV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mK8GNxFJ9vB"
      },
      "source": [
        "### Fit the model (3 Marks)\n",
        "- Specify epochs\n",
        "- Specify batch_size\n",
        "- Give validation_data\n",
        "- Validation accuracy should be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SLjprPDDYOs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diNbnH_dKO8J"
      },
      "source": [
        "### Draw plots (3 Marks)\n",
        "- Plot training accuracy and validation accuracy with respect to epochs\n",
        "- Plot training loss and validation loss with respect to epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uoIPTssDofN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}